{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839},{"sourceId":6954577,"sourceType":"datasetVersion","datasetId":3994412}],"dockerImageVersionId":30579,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/abduzzami/nih-densenet-az?scriptVersionId=150673059\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport glob\nimport itertools\nimport time\n\nimport seaborn as sns\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras import backend as K\n\nfrom tensorflow.keras.applications import EfficientNetB0, DenseNet121\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import LayerNormalization, Input, LSTM, GRU, TimeDistributed\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D, Dense, Softmax, Bidirectional, GlobalAveragePooling1D\nfrom tensorflow.keras.optimizers import Adam\n\nfrom pandas import DataFrame\nfrom typing import List\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, roc_curve","metadata":{"_uuid":"5127cec4-0861-4e36-99ce-9747e154ac3d","_cell_guid":"ea6e2702-ce21-4a67-b989-7bbcfc664a9d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:08:41.672989Z","iopub.execute_input":"2023-11-13T03:08:41.673411Z","iopub.status.idle":"2023-11-13T03:08:53.722905Z","shell.execute_reply.started":"2023-11-13T03:08:41.67336Z","shell.execute_reply":"2023-11-13T03:08:53.722066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the dataframe\ndf = pd.read_csv('/kaggle/input/data/Data_Entry_2017.csv')\n\n# Rename the columns\ndf = df.rename(columns={\n    \"OriginalImagePixelSpacing[x\": \"OriginalImagePixelSpacingX\",\n    \"y]\": \"OriginalImagePixelSpacingY\",\n    \"OriginalImage[Width\": \"OriginalImageWidth\",\n    \"Height]\": \"OriginalImageHeight\"\n})\n\n### Format the label by a one-hot encoding\n\n# Get all the label\nunique_labels = set(itertools.chain.from_iterable(df[\"Finding Labels\"].apply(lambda x: x.split('|')).values))\n\n# Convert unique_labels set to a list\nunique_labels_list = list(unique_labels)\n\n# Initialize an empty matrix\none_hot_labels = pd.DataFrame(0.0, index=np.arange(len(df)), columns=unique_labels_list)\n\n# For each row, we get the associated labels and set a 1 to the new corresponding column label\nfor index, row in df.iterrows():\n    labels = row[\"Finding Labels\"].split('|')\n    for label in labels:\n        # Clean up the label to make it suitable for a column name\n        cleaned_label = label.strip().replace(\" \", \"_\")\n        one_hot_labels.at[index, cleaned_label] = 1.0\n\n# Then, we concatenate this new dataframe to our original data\ndf = pd.concat([df, one_hot_labels], axis=1)\n\ndf.head()","metadata":{"_uuid":"5bfc1be1-95c0-4c7f-98e0-991d0724ffcf","_cell_guid":"dee5ca6d-4b19-44c7-8950-3ab0ee690e24","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:08:53.725149Z","iopub.execute_input":"2023-11-13T03:08:53.72615Z","iopub.status.idle":"2023-11-13T03:09:05.189371Z","shell.execute_reply.started":"2023-11-13T03:08:53.726111Z","shell.execute_reply":"2023-11-13T03:09:05.188347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we are going to create a test set. We will never look at this test set during the training phase.\nThis test set will allow us to measure the performance of our current model.","metadata":{"_uuid":"18825c05-f141-407a-9ade-09d9be57e349","_cell_guid":"04f35f14-e663-4299-b4db-474c0155febe","trusted":true}},{"cell_type":"code","source":"df_train, df_test = train_test_split(df, test_size = 0.33, random_state = 42)\nprint(\"Size of training set :\", len(df_train), \" - testing set:\", len(df_test))","metadata":{"_uuid":"49006ac7-1a5d-419d-baaa-38cb24ff3438","_cell_guid":"03773c3f-895d-4ff9-b99e-c382929c42ff","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:05.190474Z","iopub.execute_input":"2023-11-13T03:09:05.190793Z","iopub.status.idle":"2023-11-13T03:09:05.240587Z","shell.execute_reply.started":"2023-11-13T03:09:05.190765Z","shell.execute_reply":"2023-11-13T03:09:05.239697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"_uuid":"1308830b-9925-4631-9c7c-efa3f5b42cd3","_cell_guid":"21eb9a1f-b4d4-4c09-a6eb-d68d932837a9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:05.241881Z","iopub.execute_input":"2023-11-13T03:09:05.242552Z","iopub.status.idle":"2023-11-13T03:09:05.267951Z","shell.execute_reply.started":"2023-11-13T03:09:05.242514Z","shell.execute_reply":"2023-11-13T03:09:05.266993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Manage Data Leakage\n\nDuring our split, we could have patients from the same id in the two sets. ([See our EDA for more information](https://www.kaggle.com/rerere/eda-nih-chest-x-rays)) \nIn order to avoid data leakage, we need to remove the patient in our test set that are present in our train set. We could also do the opposite. It will depend on how much data you want in the test set.","metadata":{"_uuid":"626a9b23-6588-4d8d-9a1a-577debcdf247","_cell_guid":"47d8d0bd-baa7-4c06-ba2d-c1d82bcf9041","trusted":true}},{"cell_type":"code","source":"patient_train = set(df_train[\"Patient ID\"].values)\npatient_test  = set(df_test[\"Patient ID\"].values)\n\nleakage_patient = patient_train.intersection(patient_test)\nprint(len(leakage_patient))","metadata":{"_uuid":"2660cdd2-d55c-4804-a789-c70fe60f3770","_cell_guid":"d53b7413-3259-452b-9538-b2a0e78deac4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:05.271051Z","iopub.execute_input":"2023-11-13T03:09:05.271707Z","iopub.status.idle":"2023-11-13T03:09:05.302273Z","shell.execute_reply.started":"2023-11-13T03:09:05.271672Z","shell.execute_reply":"2023-11-13T03:09:05.301364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# How much this represent based on our set\ntrain_without_leakage = df_train[~df_train[\"Patient ID\"].isin(leakage_patient)]\n\nprint(\"Train\")\nprint(len(train_without_leakage) / len(df_train))\nprint(len(df_train))\nprint(len(train_without_leakage))\n\nprint()\nprint(\"Test\")\ntest_without_leakage = df_test[~df_test[\"Patient ID\"].isin(leakage_patient)]\nprint(len(test_without_leakage) / len(df_test))\nprint(len(df_test))\nprint(len(test_without_leakage))","metadata":{"_uuid":"11ec5dbc-a5bc-4ee9-a5f3-c701ec45afca","_cell_guid":"0ce4683a-31c0-45d6-9be4-631fbc718e4b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:05.303497Z","iopub.execute_input":"2023-11-13T03:09:05.303785Z","iopub.status.idle":"2023-11-13T03:09:05.329373Z","shell.execute_reply.started":"2023-11-13T03:09:05.303761Z","shell.execute_reply":"2023-11-13T03:09:05.328499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remvove leakage in the test\ndf_test = test_without_leakage","metadata":{"_uuid":"aa030703-c92b-4976-b15a-b8399206e608","_cell_guid":"5cecaf7f-9666-4142-aec6-1e115cdae371","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:05.330556Z","iopub.execute_input":"2023-11-13T03:09:05.330835Z","iopub.status.idle":"2023-11-13T03:09:05.337236Z","shell.execute_reply.started":"2023-11-13T03:09:05.33081Z","shell.execute_reply":"2023-11-13T03:09:05.336455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training phase\n\nFor the model, we used the EfficientNetB0 model pretrained.\n\n### Preprocessing\n\nFor the preprocessing of our data, we will simply take our gray image and duplicate the channel to obtain 3 channel in total.\nRegarding the image size, we will have an image of 224x224.\n\n> Note: For `EfficientNetB0` model, we don't need to normalize our input data. This could be a necessary step for other models.","metadata":{"_uuid":"99792d4d-70ca-403a-9ff3-fd4a5ad24e51","_cell_guid":"9f0767c8-855c-4a7a-bff3-afaf6429dbb7","trusted":true}},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/data/\"\nNB_LABELS = len(unique_labels)\nBATCH_SIZE = 32\n\nX_train, X_valid = train_test_split(df_train, test_size = 0.2, random_state = 42)","metadata":{"_uuid":"e286bbe3-1b87-47e7-8d2a-d16a6a8ca1b0","_cell_guid":"7210fac5-9af5-4ee7-8959-b0eb10a2f6ee","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:05.338721Z","iopub.execute_input":"2023-11-13T03:09:05.339047Z","iopub.status.idle":"2023-11-13T03:09:05.375065Z","shell.execute_reply.started":"2023-11-13T03:09:05.339016Z","shell.execute_reply":"2023-11-13T03:09:05.374144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class ChestImagesDataset(tf.keras.utils.Sequence):\n#     def __init__(self, df, input_folder, batch_size = 32, transform = None, training = True, shuffle = True):\n#         self.df           = df\n#         self.input_folder = input_folder\n#         self.batch_size   = batch_size\n#         self.transform    = transform\n#         self.training     = training\n#         self.shuffle      = shuffle\n        \n#     def on_epoch_end(self):\n#         if self.shuffle:\n#             self.df = self.df.sample(frac = 1).reset_index(drop = True)\n    \n#     def __len__(self):\n#         return np.ceil(len(self.df) / self.batch_size).astype(int)\n    \n#     def __getitem__(self, index):\n#         batch = self.df[index * self.batch_size : (index + 1) * self.batch_size]\n        \n#         images = []\n        \n#         for filename in batch[\"Image Index\"]:\n#             path = glob.glob(self.input_folder + \"*/*/\" + filename)[0]\n#             image = Image.open(path).convert('RGB')\n#             image = np.array(image)\n            \n#             image = tf.image.resize(image, size=(224,224))\n#             image = tf.cast(image, dtype = tf.float32)\n            \n#             images.append(image)\n        \n#         images = np.array(images)\n        \n#         if self.training:\n#             return images, np.array(batch[unique_labels].values)\n#         else: \n#             return images\n    \n# # Load the training data and the validation \n# train_generator    = ChestImagesDataset(X_train, DATA_DIR, batch_size = BATCH_SIZE, transform = None, shuffle = True)\n# valid_generator    = ChestImagesDataset(X_valid, DATA_DIR, batch_size = BATCH_SIZE, transform = None, shuffle = True)","metadata":{"_uuid":"0e5df68e-ffac-4160-a363-13bca3dbf6f1","_cell_guid":"5476a86b-5955-47ad-b0f1-4f7cec2034a4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:05.376272Z","iopub.execute_input":"2023-11-13T03:09:05.376632Z","iopub.status.idle":"2023-11-13T03:09:05.382584Z","shell.execute_reply.started":"2023-11-13T03:09:05.376598Z","shell.execute_reply":"2023-11-13T03:09:05.38161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.densenet import preprocess_input\n\nclass ChestImagesDataset(tf.keras.utils.Sequence):\n    def __init__(self, df, input_folder, batch_size=32, transform=None, training=True, shuffle=True):\n        self.df = df\n        self.input_folder = input_folder\n        self.batch_size = batch_size\n        self.transform = transform\n        self.training = training\n        self.shuffle = shuffle\n\n        # Initialize ImageDataGenerator for normalization and augmentation\n        self.datagen = ImageDataGenerator(\n#             rescale=1./255,  # Normalize pixel values to [0, 1]\n            preprocessing_function=preprocess_input  # Preprocess input for DenseNet\n            # Add more augmentation parameters as needed\n        )\n\n    def on_epoch_end(self):\n        if self.shuffle:\n            self.df = self.df.sample(frac=1).reset_index(drop=True)\n\n    def __len__(self):\n        return np.ceil(len(self.df) / self.batch_size).astype(int)\n\n    def __getitem__(self, index):\n        batch = self.df[index * self.batch_size: (index + 1) * self.batch_size]\n\n        images = []\n\n        for filename in batch[\"Image Index\"]:\n            path = glob.glob(self.input_folder + \"*/*/\" + filename)[0]\n            image = Image.open(path).convert('RGB')\n            image = np.array(image)\n\n            # Use ImageDataGenerator for normalization and preprocessing\n#             image = self.datagen.random_transform(image)\n            image = self.datagen.standardize(image)\n\n            image = tf.image.resize(image, size=(224, 224))\n            image = tf.cast(image, dtype=tf.float32)\n\n            images.append(image)\n\n        images = np.array(images)\n\n        if self.training:\n            return images, np.array(batch[list(unique_labels)].values)\n        else:\n            return images\n\n# for densenet\ntrain_generator = ChestImagesDataset(\n    X_train, DATA_DIR, batch_size=BATCH_SIZE, transform=None, shuffle=True\n)\nvalid_generator = ChestImagesDataset(\n    X_valid, DATA_DIR, batch_size=BATCH_SIZE, transform=None, shuffle=True\n)","metadata":{"_uuid":"ae01d116-7c5e-486f-a1bb-b5eef9e97bce","_cell_guid":"93964ffa-e9c6-4173-a2ae-2d1bbecd49ee","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:05.383764Z","iopub.execute_input":"2023-11-13T03:09:05.384052Z","iopub.status.idle":"2023-11-13T03:09:05.397854Z","shell.execute_reply.started":"2023-11-13T03:09:05.384028Z","shell.execute_reply":"2023-11-13T03:09:05.397034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_preprocessed_images(generator, unique_labels, num_images=5):\n    \"\"\"\n    Plot some preprocessed images from the generator.\n    \"\"\"\n    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n\n    for i in range(num_images):\n        # Generate a batch from the generator\n        batch = generator[i]\n\n        # Get the preprocessed images from the batch\n        images = batch[0]\n\n        # Convert unique_labels set to a list\n        unique_labels_list = list(unique_labels)\n\n        # Plot the preprocessed images\n        axes[i].imshow(images[0])\n        axes[i].axis('off')\n\n    plt.show()\n\n# Use the function to plot preprocessed images before training\nplot_preprocessed_images(train_generator, unique_labels)","metadata":{"_uuid":"6d53fc6e-60e5-48f3-af38-5320a2239607","_cell_guid":"4a7c4f79-81af-4fdc-a251-e346c71d3fd0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:05.398966Z","iopub.execute_input":"2023-11-13T03:09:05.399222Z","iopub.status.idle":"2023-11-13T03:09:18.668966Z","shell.execute_reply.started":"2023-11-13T03:09:05.399199Z","shell.execute_reply":"2023-11-13T03:09:18.667992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"ba6af5fa-0768-4b25-ad92-468f32a83cf3","_cell_guid":"6a5d035b-f894-453a-95f1-6483cf88a99f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MultiLabelCrossEntropy:\n    \"\"\"\n    Weight Cross Entropy Loss.\n    \n    For each class we will found two weights corresponding to the positive and negative frequency of our sample data.\n    These weights will manage the way we update our network. And this has for objectives to manage the unbalanced class issue.\n    \"\"\"\n        \n    def __init__(self, labels : DataFrame, epsilon = 1e-7):\n        \n        self.epsilon = epsilon\n        \n        # Get the size of the data\n        self.N = labels.shape[0]\n        \n        # Get the frequency occurence for each class\n        self.freq_pos = np.sum(labels == 1, axis=0) / self.N\n        self.freq_neg = np.sum(labels == 0, axis=0) / self.N\n        \n        # Set the loss weights for each labels \n        self.pos_weights = self.freq_neg\n        self.neg_weights = self.freq_pos\n        \n    def contribution(self):\n        \"\"\"\n        Get the weights' contribution for each labels.\n        \n        Returns :\n            - double : Positive contribution\n            - double : Negative contribution\n        \"\"\"\n        return self.freq_pos * self.pos_weights, self.freq_neg * self.neg_weights\n        \n        \n    def loss(self, y_true, y_pred):\n        \"\"\"\n        Return weighted loss value. \n        \"\"\"\n        # Initialize loss to zero\n        loss = 0.0\n        \n        for i in range(len(self.pos_weights)):\n            loss += (-1 * K.mean(\n                        self.pos_weights[i] * y_true[:,i] * K.log(y_pred[:,i] + self.epsilon))\n                    ) + (-1 * K.mean(\n                        self.neg_weights[i] * (1 - y_true[:,i]) * K.log(1 - y_pred[:,i] + self.epsilon))\n                    )\n        return loss","metadata":{"_uuid":"9ba1fb9e-4387-4ea8-89a7-892b64ca7ffb","_cell_guid":"96e0ac72-bbb8-4239-abcb-d159b08ebe5f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:18.670068Z","iopub.execute_input":"2023-11-13T03:09:18.670395Z","iopub.status.idle":"2023-11-13T03:09:18.683692Z","shell.execute_reply.started":"2023-11-13T03:09:18.670366Z","shell.execute_reply":"2023-11-13T03:09:18.682396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cross_entropy_loss = MultiLabelCrossEntropy(X_train[list(unique_labels)])\n\n\npos_contribution, neg_contribution = cross_entropy_loss.contribution()","metadata":{"_uuid":"49347373-d242-4aaf-a0bd-4135248b5ccb","_cell_guid":"8df1ae8d-34d5-4aa6-be37-40def508ce30","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:18.685292Z","iopub.execute_input":"2023-11-13T03:09:18.685879Z","iopub.status.idle":"2023-11-13T03:09:18.717278Z","shell.execute_reply.started":"2023-11-13T03:09:18.685844Z","shell.execute_reply":"2023-11-13T03:09:18.716515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nlabels = list(unique_labels)\n\ndata = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": pos_contribution})\ndata = pd.concat([data, pd.DataFrame({\"Class\": labels, \"Label\": \"Negative\", \"Value\": neg_contribution})], ignore_index=True)\nplt.xticks(rotation=90)\nsns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\", data=data)\nplt.show()\n","metadata":{"_uuid":"22fa1106-1a53-40ce-b0fc-55cf8e0823a2","_cell_guid":"55e34bda-9296-4c30-b95e-c75f008044d7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:18.722103Z","iopub.execute_input":"2023-11-13T03:09:18.722384Z","iopub.status.idle":"2023-11-13T03:09:19.162138Z","shell.execute_reply.started":"2023-11-13T03:09:18.72236Z","shell.execute_reply":"2023-11-13T03:09:19.161113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note : For the model, we could use other alternatives as DenseNet ...","metadata":{"_uuid":"ce661419-d76a-4d4c-a086-b79a58dad513","_cell_guid":"453e3864-a2d9-4954-999c-b110e80360c1","trusted":true}},{"cell_type":"code","source":"# def create_efficientB_model(cross_entropy_loss):\n    \n#     inputs = Input(shape=(224, 224, 3))\n#     model = EfficientNetB0(input_tensor=inputs, weights='imagenet', include_top=False)\n#     model.trainable = False # Freeze the layer\n    \n#     # Rebuild top\n#     x = GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n#     x = BatchNormalization()(x)\n\n#     x = Dropout(0.2, name=\"top_dropout\")(x)\n#     outputs = Dense(NB_LABELS, activation=\"sigmoid\", name=\"pred\")(x)\n    \n#     # Compile\n#     model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n    \n#     # Note : Possibility to assign a learning rate.\n#     model.compile(optimizer=Adam(), \n#                   loss = cross_entropy_loss.loss,\n#                   metrics=[\n#         'accuracy',\n#         tf.keras.metrics.Recall(),\n#         tfa.metrics.F1Score(num_classes = NB_LABELS, threshold=0.5),\n#         tf.keras.metrics.AUC(multi_label = True)\n#     ])\n    \n#     return model\n\n# model = create_efficientB_model(cross_entropy_loss)","metadata":{"_uuid":"d0e2e7ed-288f-4971-afad-3dad1e1a681e","_cell_guid":"333c27f1-d861-434f-a7ef-bd015559a2c4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:19.163242Z","iopub.execute_input":"2023-11-13T03:09:19.163557Z","iopub.status.idle":"2023-11-13T03:09:19.169441Z","shell.execute_reply.started":"2023-11-13T03:09:19.163529Z","shell.execute_reply":"2023-11-13T03:09:19.168495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_densenet_model(cross_entropy_loss):\n    base_model = DenseNet121(\n        include_top=False, weights=\"imagenet\", input_tensor=Input(shape=(224, 224, 3))\n    )\n    base_model.trainable = False  # Freeze the layer\n\n    # Rebuild top\n    x = GlobalAveragePooling2D(name=\"avg_pool\")(base_model.output)\n    x = BatchNormalization()(x)\n    x = Dropout(0.2, name=\"top_dropout\")(x)\n    outputs = Dense(NB_LABELS, activation=\"sigmoid\", name=\"pred\")(x)\n\n    # Compile\n    model = Model(base_model.input, outputs, name=\"DenseNet\")\n    model.compile(\n        optimizer=Adam(),\n        loss=cross_entropy_loss.loss,\n        metrics=[\n            tf.keras.metrics.BinaryAccuracy(),\n            tf.keras.metrics.Recall(),\n            tfa.metrics.F1Score(num_classes=NB_LABELS, threshold=0.5),\n            tf.keras.metrics.AUC(multi_label=True),\n        ],\n    )\n\n    return model\n\nmodel = create_densenet_model(cross_entropy_loss)","metadata":{"_uuid":"eb33e154-ccce-48b6-ad0e-47f899f7d173","_cell_guid":"d2166863-825f-451b-8eea-02b2b2d47728","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:19.170651Z","iopub.execute_input":"2023-11-13T03:09:19.170998Z","iopub.status.idle":"2023-11-13T03:09:25.514527Z","shell.execute_reply.started":"2023-11-13T03:09:19.170963Z","shell.execute_reply":"2023-11-13T03:09:25.513583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history = model.fit(train_generator, validation_data=valid_generator, epochs = 8, batch_size = BATCH_SIZE)","metadata":{"_uuid":"78c3ead2-d670-41d9-82c3-260e7c0ae571","_cell_guid":"e26a0815-b3b2-4e68-8371-022cb216c018","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:25.515872Z","iopub.execute_input":"2023-11-13T03:09:25.516551Z","iopub.status.idle":"2023-11-13T03:09:25.52067Z","shell.execute_reply.started":"2023-11-13T03:09:25.516513Z","shell.execute_reply":"2023-11-13T03:09:25.519807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '/kaggle/input/output/model'\nmodel = tf.keras.models.load_model(model_path, custom_objects={'loss': cross_entropy_loss.loss})","metadata":{"execution":{"iopub.status.busy":"2023-11-13T03:23:44.638654Z","iopub.execute_input":"2023-11-13T03:23:44.639601Z","iopub.status.idle":"2023-11-13T03:24:01.552817Z","shell.execute_reply.started":"2023-11-13T03:23:44.639558Z","shell.execute_reply":"2023-11-13T03:24:01.551879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model \nmodel.save(\"model\")","metadata":{"_uuid":"d4703e75-b07c-4704-95ef-12af4fe1e1b5","_cell_guid":"a72918a5-78e0-4a47-904a-6b44b1fabdec","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:40:08.129354Z","iopub.execute_input":"2023-11-13T03:40:08.130264Z","iopub.status.idle":"2023-11-13T03:40:46.489769Z","shell.execute_reply.started":"2023-11-13T03:40:08.130226Z","shell.execute_reply":"2023-11-13T03:40:46.488867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\n\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"_uuid":"ea5453c3-3f00-490d-874b-bd0e34f257fe","_cell_guid":"ef6667dc-d666-4286-8b60-d09f6a66d963","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:30:16.753899Z","iopub.execute_input":"2023-11-13T03:30:16.754359Z","iopub.status.idle":"2023-11-13T03:30:16.801992Z","shell.execute_reply.started":"2023-11-13T03:30:16.754325Z","shell.execute_reply":"2023-11-13T03:30:16.800705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['binary_accuracy'])\nplt.plot(history.history['val_accuracy'])\n\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"_uuid":"b297a483-5933-4bd0-8aaf-770707adffd8","_cell_guid":"fd2e0389-c588-4e85-a61d-c185d5ebb675","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:42.68481Z","iopub.status.idle":"2023-11-13T03:09:42.685271Z","shell.execute_reply.started":"2023-11-13T03:09:42.685037Z","shell.execute_reply":"2023-11-13T03:09:42.685059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['recall_1'])\nplt.plot(history.history['val_recall_1'])\n\nplt.title('model recall')\nplt.ylabel('recall_1')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"_uuid":"44b53c39-258d-462d-b773-6b9ae5853ebc","_cell_guid":"964e7393-7795-47f5-946e-a1e83d813974","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:42.686664Z","iopub.status.idle":"2023-11-13T03:09:42.687147Z","shell.execute_reply.started":"2023-11-13T03:09:42.686931Z","shell.execute_reply":"2023-11-13T03:09:42.686955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['f1_score'])\nplt.plot(history.history['val_f1_score'])\n\nplt.title('model f1_score')\nplt.ylabel('f1_score')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"_uuid":"001ecc65-66d8-4c8b-b24f-13ae19cc49cb","_cell_guid":"150113d4-b61f-495e-a403-d0dd7f8e3ec4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:42.688495Z","iopub.status.idle":"2023-11-13T03:09:42.688881Z","shell.execute_reply.started":"2023-11-13T03:09:42.688708Z","shell.execute_reply":"2023-11-13T03:09:42.688725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['auc_1'])\nplt.plot(history.history['val_auc_1'])\n\nplt.title('model auc')\nplt.ylabel('auc_1')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"_uuid":"7018f7d6-216c-46f5-8ff3-942a24d5b0bc","_cell_guid":"5dfe2173-23ef-40ee-b269-3d7f8461df5b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:09:42.691893Z","iopub.status.idle":"2023-11-13T03:09:42.692331Z","shell.execute_reply.started":"2023-11-13T03:09:42.692113Z","shell.execute_reply":"2023-11-13T03:09:42.692133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test phase","metadata":{"_uuid":"72bad0fb-d1ab-4560-afe9-fe29f70cea14","_cell_guid":"26ca7c55-2adb-42f6-aef1-8c2476c70a76","trusted":true}},{"cell_type":"code","source":"test_generator = ChestImagesDataset(df_test, DATA_DIR, batch_size = BATCH_SIZE, transform = None, training = False, shuffle = False)\n\npredictions = model.predict(test_generator)","metadata":{"_uuid":"01c17f3a-79a3-4c1b-90af-fdc12e07da99","_cell_guid":"909b6826-2d92-4dd1-a068-83e02e8bca2e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:30:32.451655Z","iopub.execute_input":"2023-11-13T03:30:32.452404Z","iopub.status.idle":"2023-11-13T03:37:47.492343Z","shell.execute_reply.started":"2023-11-13T03:30:32.452371Z","shell.execute_reply":"2023-11-13T03:37:47.491508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_auc_score(df_test[list(unique_labels)].values, predictions)","metadata":{"_uuid":"7fc41478-c0ba-4662-b373-cb3366a5e5fd","_cell_guid":"730f74e7-755d-45aa-b5cb-7d401b3dfe21","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:43:29.479588Z","iopub.execute_input":"2023-11-13T03:43:29.480298Z","iopub.status.idle":"2023-11-13T03:43:29.577994Z","shell.execute_reply.started":"2023-11-13T03:43:29.480266Z","shell.execute_reply":"2023-11-13T03:43:29.576679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Metrics\n\ndef get_roc_curve(labels, predicted_vals, real_vals):\n    auc_roc_vals = []\n    for i in range(len(labels)):\n        try:\n            gt = real_vals[:, i]\n            pred = predicted_vals[:, i]\n            auc_roc = roc_auc_score(gt, pred)\n            auc_roc_vals.append(auc_roc)\n            fpr_rf, tpr_rf, _ = roc_curve(gt, pred)\n            plt.figure(1, figsize=(10, 10))\n            plt.plot([0, 1], [0, 1], 'k--')\n            plt.plot(fpr_rf, tpr_rf,\n                     label=labels[i] + \" (\" + str(round(auc_roc, 3)) + \")\")\n            plt.xlabel('False positive rate')\n            plt.ylabel('True positive rate')\n            plt.title('ROC curve')\n            plt.legend(loc='best')\n        except:\n            print(\n                f\"Error in generating ROC curve for {labels[i]}. \"\n                f\"Dataset lacks enough examples.\"\n            )\n    plt.show()\n    return auc_roc_vals\n\n\nget_roc_curve(list(unique_labels), predictions, df_test[list(unique_labels)].values)","metadata":{"_uuid":"2238a1e4-4401-4919-884b-05afb0d3cae3","_cell_guid":"6bc54976-82e5-4db1-8d49-2c906f4c66a6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-11-13T03:43:19.10171Z","iopub.execute_input":"2023-11-13T03:43:19.102055Z","iopub.status.idle":"2023-11-13T03:43:19.725819Z","shell.execute_reply.started":"2023-11-13T03:43:19.102027Z","shell.execute_reply":"2023-11-13T03:43:19.724919Z"},"trusted":true},"execution_count":null,"outputs":[]}]}